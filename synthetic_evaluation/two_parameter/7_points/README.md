### Info
 
To evaluate and compare the accuracy of both modeler for two parameter models we use two different approaches:
 
First, we analyze the scaling of a model at the next measurement point for x and y that was not used for modeling. Since we used x={4,8,16,32,64,128,256} and y={10,20,30,40,50,60,70} for modeling this point is x=512,y=80. Then we check if the predicted value at this point is within noise (+-5%), 2x, 3x, 4x and 5x times the noise. 5x noise equals a divergence of +-25% to the actual measured value. If this is the case then we count the model as correct. Furthermore, we also check the scaling at the next point where x=1024, y=90. Additionally, we also only scale one axis at a time, e.g. keeping x=4 while scaling y=80. Each plot presentes the number of correct models, considering different noise bands, at a specific point with a different number of repetitions R={1,2,3,4,5,6,7}, sorted by the modeler configuration. B25 stands for the baseline (old) modeler that uses all 25 points for modeling. S stands for the sparse modeler, followed by the number of points that it uses for modeling.
 
Second, we analyze the model correctness by taking a look at the correctly identified function terms. Therefore, for each model we identify if the function is identical, if the lead order term (the term with the biggest contribution to the modeled behaviour) is correct, or if the model is incorrect. Every plot shows the percentages of models depending on the modeler (old or new) and its configuration (B25, S9, S10) for a specific number of repetitions per measurement point when using 7 points for modeling per parameter.
